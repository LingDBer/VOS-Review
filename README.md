## [Deep Learning for Video Object Segmentation: A Review]() (TODO: paper link)

This repo is built to facilitate access to the related VOS datasets and papers (with code links if applicable). 

中文版博客[链接]() (TODO: blog link)

If you find our review and repository useful for your research, please consider citing our paper:

```bibtex
TODO: article bibtex
```

## Content

- [Section 3. Datasets](#section-3-datasets)
- [Section 4. Methods](#section-4-methods)
  - [4.1. Online Fine-tuning-based VOS](#41-online-fine-tuning-based-vos)
  - [4.2. Feature Matching-based VOS](#42-feature-matching-based-vos)
  - [4.3. Graph Optimisation-based VOS](#43-graph-optimisation-based-vos)
  - [4.4. Optical Flow-based VOS](#44-optical-flow-based-vos)
  - [4.5. Mask Propagation-based VOS](#45-mask-propagation-based-vos)
  - [4.6. Long-term Propagation-based VOS](#46-long-term-propagation-based-vos)

## Section 3. Datasets

#### Earlier datasets for VOS evaluation
|Years|Datasets with links|
|:-:|---|
|2007|[Hopkins 155](http://www.vision.jhu.edu/data/hopkins155/)|

## Section 4. Methods
TODO: tables showing the pdf and code links of the reviewed papers

### 4.1. Online Fine-tuning-based VOS

|Paper titles with links (abbreviates in our review)|Venues|Years|Codes|
|---|:-:|:-:|:-:|
|[One-Shot Video Object Segmentation](https://openaccess.thecvf.com/content_cvpr_2017/papers/Caelles_One-Shot_Video_Object_CVPR_2017_paper.pdf) (OSVOS)|CVPR|2017|[PyTorch](https://github.com/kmaninis/OSVOS-PyTorch)|
|[Online Adaptation of Convolutional Neural Networks for Video Object Segmentation](https://arxiv.org/pdf/1706.09364.pdf) (OnAVOS)|BMVC|2017|[Tenserflow](https://www.vision.rwth-aachen.de/page/OnAVOS)|
|[Video Object Segmentation without Temporal Information](https://ieeexplore.ieee.org/document/8362936) (OSVOS-S)|TPAMI|2018|[Website](https://cvlsegmentation.github.io/osvos-s/)|
|[Video Object Segmentation by Learning Location-Sensitive Embeddings](https://www.ecva.net/papers/eccv_2018/papers_ECCV/papers/Hai_Ci_Video_Object_Segmentation_ECCV_2018_paper.pdf) (LSE-VOS)|ECCV|2018||
|[Lucid Data Dreaming for Video Object Segmentation](https://link.springer.com/article/10.1007/s11263-019-01164-6)|IJCV|2019|[MATLAB](https://github.com/ankhoreva/LucidDataDreaming)|
|[BubbleNets: Learning to Select the Guidance Frame in Video Object Segmentation by Deep Sorting Frames](https://openaccess.thecvf.com/content_CVPR_2019/papers/Griffin_BubbleNets_Learning_to_Select_the_Guidance_Frame_in_Video_Object_CVPR_2019_paper.pdf)|CVPR|2019|[Tensorflow](https://github.com/griffbr/BubbleNets)|

#### Variants

|Paper titles with links (abbreviates in our review)|Venues|Years|Codes|
|---|:-:|:-:|:-:|
|[Efficient Video Object Segmentation via Network Modulation](https://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_Efficient_Video_Object_CVPR_2018_paper.pdf) (OSMN)|CVPR|2018|[Tensorflow](https://github.com/linjieyangsc/video_seg)|
|[A Generative Appearance Model for End-to-end Video Object Segmentation](https://openaccess.thecvf.com/content_CVPR_2019/papers/Johnander_A_Generative_Appearance_Model_for_End-To-End_Video_Object_Segmentation_CVPR_2019_paper.pdf) (AGAME)|CVPR|2019|[PyTorch](https://github.com/joakimjohnander/agame-vos)|
|[Learning Fast and Robust Target Models for Video Object Segmentation](https://openaccess.thecvf.com/content_CVPR_2020/papers/Robinson_Learning_Fast_and_Robust_Target_Models_for_Video_Object_Segmentation_CVPR_2020_paper.pdf) (FRTM)|CVPR|2020|[PyTorch](https://github.com/andr345/frtm-vos)|
|[Learning What to Learn for Video Object Segmentation](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123470766.pdf) (LWL)|ECCV|2020|[PyTorch](https://github.com/visionml/pytracking)|
|[Target-Aware Object Discovery and Association for Unsupervised Video Multi-Object Segmentation](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Target-Aware_Object_Discovery_and_Association_for_Unsupervised_Video_Multi-Object_Segmentation_CVPR_2021_paper.pdf) (TAODA)|CVPR|2021||

### 4.2. Feature Matching-based VOS

table

### 4.3. Graph Optimisation-based VOS

table

### 4.4. Optical Flow-based VOS

table

### 4.5. Mask Propagation-based VOS

table

### 4.6. Long-term Propagation-based VOS

table
